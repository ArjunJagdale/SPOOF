<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Anti-Spoof Live</title>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<style>
  body { text-align:center; font-family:Arial; }

  .video-wrapper {
    position: relative;
    width: min(400px, 92vw);
    height: min(400px, 92vw);
    margin: 0 auto;
  }

  video {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transform: scaleX(-1); /* mirror front camera preview */
  }

  /* Oval mask */
  .video-wrapper::after {
    content: "";
    position: absolute;
    inset: 0;
    pointer-events: none;

    /* Dark overlay with transparent oval cutout */
    background:
      radial-gradient(
        ellipse 50% 80% at center,
        transparent 0%,
        transparent 80%,
        rgba(0,0,0,0.65) 61%
      );
  }
</style>
</head>
<body>

<h2 style="font-size:30px; margin-bottom:6px;">Live Anti-Spoof</h2>

<p style="font-size:15px; color:#444; max-width:360px; margin:8px auto 16px; line-height:1.4;">
  • Ensure your face is clearly visible in good lighting (avoid harsh reflections).<br>
  • Align and fit your face tightly within the oval.
</p>

<div class="video-wrapper">
  <video id="video" width="224" height="224" autoplay playsinline></video>
</div>

<canvas id="canvas" width="224" height="224" style="display:none;"></canvas>
<p id="result">Loading model...</p>

<script>
let session;

async function init() {
  session = await ort.InferenceSession.create("antispoof_model.onnx");
  document.getElementById("result").innerText = "Model loaded. Starting camera...";
  startCamera();
}

async function startCamera() {
  const video = document.getElementById("video");

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" }
  });

  video.srcObject = stream;
  runLoop();
}

async function runLoop() {
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  // Un-mirror the canvas draw so the model sees the correct (non-flipped) image
  ctx.save();
  ctx.scale(-1, 1);
  ctx.drawImage(video, -224, 0, 224, 224);
  ctx.restore();

  const imageData = ctx.getImageData(0, 0, 224, 224).data;

  const floatData = new Float32Array(1 * 3 * 224 * 224);

  const mean = [0.485, 0.456, 0.406];
  const std  = [0.229, 0.224, 0.225];

  for (let i = 0; i < 224 * 224; i++) {
    const r = imageData[i * 4] / 255;
    const g = imageData[i * 4 + 1] / 255;
    const b = imageData[i * 4 + 2] / 255;

    floatData[i]             = (r - mean[0]) / std[0];
    floatData[i + 224*224]   = (g - mean[1]) / std[1];
    floatData[i + 2*224*224] = (b - mean[2]) / std[2];
  }

  const tensor = new ort.Tensor("float32", floatData, [1, 3, 224, 224]);
  const results = await session.run({ input: tensor });

  const logit = results.output.data[0];
  const prob = 1 / (1 + Math.exp(-logit));

  document.getElementById("result").innerText =
    prob > 0.5 ? `REAL (${prob.toFixed(3)})` :
                 `ATTACK (${prob.toFixed(3)})`;

  requestAnimationFrame(runLoop);
}

init();
</script>

</body>
</html>
